{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as f\n",
    "import torch.nn as nn\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_data=False\n",
    "convert_data=False\n",
    "model_exists=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if create_data:\n",
    "    cap=cv2.VideoCapture(0)\n",
    "    file='data\\\\left'\n",
    "    i=0\n",
    "    while i<500:\n",
    "        name='left'\n",
    "        name=name+str(i)+'.jpg'\n",
    "        i+=1\n",
    "        ret,frame=cap.read()\n",
    "        try:\n",
    "            cv2.imshow('frame',frame)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        if cv2.waitKey(100) & 0xFF == ord('q'):\n",
    "            break\n",
    "        p=os.path.join(file,name)\n",
    "        cv2.imwrite(p,frame)\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if convert_data:\n",
    "    data_file='data'\n",
    "    labels=['right','left','idle']\n",
    "    data=[]\n",
    "    for label in labels:\n",
    "        path=os.path.join(data_file,label)\n",
    "        for file in tqdm(os.listdir(path)):\n",
    "            try:\n",
    "                image=cv2.imread(os.path.join(path,file))\n",
    "                image=cv2.resize(image,(50,50))\n",
    "                image=cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "                d=np.array([image,label])\n",
    "                data.append(d)\n",
    "            except:\n",
    "                print('h')\n",
    "    data=np.array(data)\n",
    "    np.random.shuffle(data)\n",
    "    np.save('data.npy',data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=np.load('data.npy',allow_pickle=True)\n",
    "cv2.imshow('pic',data[2][0])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size=int(data.shape[0]*0.1)\n",
    "training_data=data[:-test_size]\n",
    "test_data=data[-test_size:]\n",
    "actions={'left':0,'right':1,'idle':2}\n",
    "dc={'dog':0,'cat':1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_x=[]\n",
    "training_y=[]\n",
    "test_set=[]\n",
    "for x in training_data:\n",
    "    training_x.append(x[0]/255)\n",
    "#     print(x[1])\n",
    "#     training_y.append(x[1])\n",
    "    training_y.append(np.eye(3)[actions[x[1]]])\n",
    "training_x=torch.Tensor(training_x)\n",
    "# print(training_y)\n",
    "training_y=torch.Tensor(training_y)\n",
    "\n",
    "for x in test_data:\n",
    "    k=np.array([x[0],np.eye(3)[actions[x[1]]]])\n",
    "    test_set.append(k)\n",
    "# test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1=nn.Conv2d(1,50,5)\n",
    "        self.conv2=nn.Conv2d(50,100,5)\n",
    "        self.conv3=nn.Conv2d(100,200,5)\n",
    "        self.flat=-1\n",
    "        \n",
    "        self.flatten()\n",
    "        \n",
    "        self.fc1=nn.Linear(self.flat,self.flat)\n",
    "        self.fc2=nn.Linear(self.flat,100)\n",
    "        self.fc3=nn.Linear(100,3)\n",
    "    \n",
    "    def flatten(self):\n",
    "        x=np.random.rand(50,50)\n",
    "#         print(x)\n",
    "        x=torch.Tensor(x).view(-1,1,50,50)\n",
    "        x=(f.max_pool2d(self.conv1(x),(2,2)))\n",
    "        x=(f.max_pool2d(self.conv2(x),(2,2)))\n",
    "        x=(f.max_pool2d(self.conv3(x),(2,2)))\n",
    "#         print(x.shape)\n",
    "        self.flat=x.shape[1]*x.shape[2]*x.shape[3]\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x=f.relu(f.max_pool2d(self.conv1(x),(2,2)))\n",
    "        x=f.relu(f.max_pool2d(self.conv2(x),(2,2)))\n",
    "        x=f.relu(f.max_pool2d(self.conv3(x),(2,2)))\n",
    "        x=f.relu(self.fc1(x.view(-1,self.flat)))\n",
    "        x=f.relu(self.fc2(x))\n",
    "        x=f.relu(self.fc3(x))\n",
    "#         print(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device=torch.device('cuda:0')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "net=Net().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.08604913 0.97304405 0.2938683  ... 0.1098536  0.71497969 0.3464271 ]\n",
      " [0.49135731 0.82080028 0.74050852 ... 0.68763181 0.65733556 0.62742797]\n",
      " [0.94349731 0.86496495 0.9150428  ... 0.93833072 0.88621613 0.73920402]\n",
      " ...\n",
      " [0.07866425 0.22788643 0.82138235 ... 0.65496799 0.81955757 0.84022921]\n",
      " [0.3586896  0.52371193 0.74841534 ... 0.47844935 0.22991434 0.54340015]\n",
      " [0.18809612 0.4158535  0.76346885 ... 0.56049785 0.78805604 0.59185474]]\n"
     ]
    }
   ],
   "source": [
    "x=np.random.rand(50,50)\n",
    "print(x)\n",
    "x=torch.Tensor(x).view(-1,1,50,50).to(device)\n",
    "y=net.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 24.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1102, device='cuda:0', grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 20.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1079, device='cuda:0', grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 14/14 [00:01<00:00, 11.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0347, device='cuda:0', grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "optimizer=optim.Adam(net.parameters(),lr=0.001)\n",
    "loss_func=nn.MSELoss()\n",
    "epochs=3\n",
    "batch_size=100\n",
    "for epoch in range(epochs):\n",
    "    for i in tqdm(range(0,training_data.shape[0],batch_size)):\n",
    "        net.zero_grad()\n",
    "        x=training_x[i:i+batch_size].to(device)\n",
    "        y=training_y[i:i+batch_size].to(device)\n",
    "        output=net(x.view(-1,1,50,50))\n",
    "        loss=loss_func(output,y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "correct=0\n",
    "total=0\n",
    "for i in test_set:\n",
    "    x=torch.Tensor(i[0]/255).view(-1,50,50).to(device)\n",
    "    y=torch.argmax(torch.Tensor(i[1])).to(device)\n",
    "    output=net(x.view(-1,1,50,50))\n",
    "    if y==torch.argmax(output):\n",
    "        correct+=1\n",
    "    total+=1\n",
    "print(correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap=cv2.VideoCapture(0)\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "while True:\n",
    "    ret,frame=cap.read()\n",
    "    x=cv2.resize(frame,(50,50))\n",
    "    x=cv2.cvtColor(x, cv2.COLOR_BGR2GRAY)\n",
    "    x=x/255\n",
    "    x=torch.Tensor(x).view(-1,1,50,50).to(device)\n",
    "    output=torch.argmax(net(x))\n",
    "    cv2.namedWindow('frame',cv2.WINDOW_NORMAL)\n",
    "    if output==1:\n",
    "        cv2.putText(frame,'right',(10,200), font, 1, (200,255,123), 3, cv2.LINE_AA)\n",
    "#         print('right')\n",
    "    elif output==2:\n",
    "        pass\n",
    "    else:\n",
    "#         print('left')\n",
    "        cv2.putText(frame,'left',(550,200), font, 1, (200,32,155), 3, cv2.LINE_AA)\n",
    "    if cv2.waitKey(300) & 0xFF == ord('q'):\n",
    "        break\n",
    "    cv2.imshow('frame',frame)\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap=cv2.VideoCapture(0)\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "while True:\n",
    "    ret,frame=cap.read()\n",
    "    if cv2.waitKey(5) & 0xFF == ord('q'):\n",
    "        break\n",
    "    cv2.imshow('frame',frame)\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
